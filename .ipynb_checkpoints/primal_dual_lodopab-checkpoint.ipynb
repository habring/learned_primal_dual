{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Notebook exemplifies using the learned primal-dual reconstruction method on the LoDoPaB-CT dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import odl\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from primaldual import LearnedPrimalDual\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torchvision.transforms import ToTensor\n",
    "import torchvision\n",
    "from tqdm.auto import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.1\n"
     ]
    }
   ],
   "source": [
    "t = torch.tensor([1.])\n",
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters\n",
    "(not necessarily good settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 1e-3\n",
    "NUM_EPOCHS = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_np(tensor):\n",
    "    return tensor.cpu().detach().numpy()\n",
    "\n",
    "def show_img(tensor, title=None):\n",
    "    plt.figure()\n",
    "    plt.imshow(to_np(tensor), cmap='Greys_r')\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up ODL operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class adj_FFT_subsampling(odl.Operator):\n",
    "    def __init__(self, range, mask=1.0+0.0j):\n",
    "        \n",
    "        domain = odl.uniform_discr(min_pt=[0.,0.], max_pt=[27.,54.], shape=(range.shape[0],2*range.shape[1]),\n",
    "                          dtype=np.float32)\n",
    "        \n",
    "        super(adj_FFT_subsampling, self).__init__(\n",
    "                domain, range, linear=True)\n",
    "        \n",
    "        self.shape = range.shape\n",
    "        self.mask = mask\n",
    "        \n",
    "    def _call(self, x, out, **kwargs):\n",
    "        t = x.asarray()\n",
    "        tmp = t[:,:self.shape[1]]+1.0j*t[:,self.shape[1]:]\n",
    "        tmp = tmp*self.mask\n",
    "        out[:] = np.real(np.fft.ifft2(tmp,norm = 'ortho'))\n",
    "    \n",
    "    @property\n",
    "    def adjoint(self):\n",
    "        return FFT_subsampling(domain=self.range, mask = self.mask)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FFT_subsampling(odl.Operator):\n",
    "    def __init__(self, domain, mask=1.0+0.0j):\n",
    "        \n",
    "        range = odl.uniform_discr(min_pt=[0.,0.], max_pt=[27.,54.], shape=(domain.shape[0],2*domain.shape[1]),\n",
    "                          dtype=np.float32)\n",
    "        \n",
    "        super(FFT_subsampling, self).__init__(\n",
    "                domain, range, linear=True)\n",
    "        \n",
    "        self.shape = domain.shape\n",
    "        self.mask = mask\n",
    "        \n",
    "    def _call(self, x, out, **kwargs):\n",
    "        tmp = np.fft.fft2(x.asarray(),norm = 'ortho')\n",
    "        tmp = tmp*self.mask\n",
    "        out[:] = np.concatenate([np.real(tmp), np.imag(tmp)], axis=1)\n",
    "        \n",
    "    \n",
    "    @property\n",
    "    def adjoint(self):\n",
    "        return adj_FFT_subsampling(range=self.domain, mask = self.mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ~26cm x 26cm images\n",
    "MIN_PT = [-0.13, -0.13]\n",
    "MAX_PT = [0.13, 0.13]\n",
    "\n",
    "# image shape for simulation\n",
    "IM_SHAPE = (28, 28)\n",
    "\n",
    "mask = np.zeros(IM_SHAPE, dtype = np.complex64)\n",
    "\n",
    "mask[0:5,:] = 1\n",
    "mask[12:14,:] = 1\n",
    "#mask[:]=1\n",
    "\n",
    "space = odl.uniform_discr(min_pt=MIN_PT, max_pt=MAX_PT, shape=IM_SHAPE,\n",
    "                          dtype=np.float32)\n",
    "\n",
    "fw_op = odl.operator.default_ops.IdentityOperator(space)\n",
    "fw_op = FFT_subsampling(space,mask)\n",
    "adj_fw_op = adj_FFT_subsampling(space,mask)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create LoDoPaB-CT Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class custom_dataset(Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x, y = self.dataset.__getitem__(idx)\n",
    "        y = fw_op(x.squeeze()).asarray()\n",
    "        #y = np.concat()\n",
    "        return y, x.squeeze()\n",
    "        #return x.squeeze()+0.2*(x.max()-x.min())*torch.randn(*x.squeeze().shape), x.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = torchvision.datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "training_dataset = custom_dataset(training_dataset)\n",
    "#training_dataset, valid_dataset = torch.utils.data.random_split(training_dataset, [len(training_dataset)//2,len(training_dataset)-len(training_dataset)//2])\n",
    "training_dataset, valid_dataset = torch.utils.data.random_split(training_dataset, [100,len(training_dataset)-100])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = DataLoader(training_dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "show_img(torch.tensor(training_dataset[0][0]), 'Noisy')\n",
    "show_img(torch.tensor(adj_fw_op(training_dataset[0][0]).asarray()), 'FFT')\n",
    "show_img(training_dataset[0][1], 'Ground truth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PinballLoss():\n",
    "    def __init__(self, quantile=0.10, reduction='mean'):\n",
    "        self.quantile = quantile\n",
    "        assert 0 < self.quantile\n",
    "        assert self.quantile < 1\n",
    "        self.reduction = reduction\n",
    "        \n",
    "    def __call__(self, output, target):\n",
    "        assert output.shape == target.shape\n",
    "        loss = torch.zeros_like(target, dtype=torch.float)\n",
    "        error = output - target\n",
    "        smaller_index = error < 0\n",
    "        bigger_index = 0 < error\n",
    "        loss[smaller_index] = self.quantile * (abs(error)[smaller_index])\n",
    "        loss[bigger_index] = (1-self.quantile) * (abs(error)[bigger_index])\n",
    "        \n",
    "        if self.reduction == 'sum':\n",
    "            loss = loss.sum()\n",
    "        if self.reduction == 'mean':\n",
    "            loss = loss.mean()\n",
    "        \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class pd_model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.q_hi = LearnedPrimalDual(fw_op)\n",
    "        self.q_low = LearnedPrimalDual(fw_op)\n",
    "        self.mean = LearnedPrimalDual(fw_op)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        lower = self.q_low(x)\n",
    "        upper = self.q_hi(x)\n",
    "        pred = self.mean(x)\n",
    "        \n",
    "        lower = torch.min(pred-1e-6,lower)\n",
    "        upper = torch.max(pred+1e-6,upper)\n",
    "        \n",
    "        return lower, pred, upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.1\n",
    "def my_loss(pred, target):\n",
    "    q_lo_loss = PinballLoss(quantile=alpha/2)\n",
    "    q_hi_loss = PinballLoss(quantile=1-alpha/2)\n",
    "    mse_loss = torch.nn.MSELoss()\n",
    "    return q_lo_loss(pred[0],target) + mse_loss(pred[1],target) + q_hi_loss(pred[2],target)\n",
    "\n",
    "model = pd_model()\n",
    "#model = LearnedPrimalDual(fw_op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_curve = []\n",
    "epoch = 0\n",
    "optimizer = torch.optim.Adam(\n",
    "    list(model.parameters()),\n",
    "    lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('go')\n",
    "model.to('cuda:0')\n",
    "print('train:')\n",
    "model = model.train()\n",
    "num_epochs = NUM_EPOCHS\n",
    "print('start')\n",
    "for epoch in range(1,num_epochs+1):\n",
    "    print('Epoch: '+str(epoch)+'/'+str(num_epochs))\n",
    "    for (noisy, ground_truth) in tqdm(data_loader):\n",
    "        # add channel dimensions\n",
    "        noisy = torch.unsqueeze(noisy, 1).to('cuda:0') \n",
    "        ground_truth = torch.unsqueeze(ground_truth, 1).to('cuda:0')\n",
    "\n",
    "        output = model(noisy)\n",
    "        loss = my_loss(output,ground_truth)\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "torch.save(model.state_dict(), 'model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_idx = torch.randint(len(valid_dataset), size=(10,))\n",
    "cols = 3\n",
    "model.to('cpu')\n",
    "with torch.no_grad():\n",
    "    for i in range(3):\n",
    "        noisy,img = valid_dataset[sample_idx[i].item()]\n",
    "        figure = plt.figure()\n",
    "        figure.set_size_inches(16, 10)\n",
    "        figure.add_subplot(1, cols, 1)\n",
    "        plt.axis(\"off\")\n",
    "        plt.title('Noisy')\n",
    "        plt.imshow(noisy.squeeze(), cmap=\"gray\")\n",
    "        figure.add_subplot(1, cols, 2)\n",
    "        plt.axis(\"off\")\n",
    "        plt.title('Ground truth')\n",
    "        plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "        figure.add_subplot(1, cols, 3)\n",
    "        plt.axis(\"off\")\n",
    "        plt.title('Recon')\n",
    "        plt.imshow(model(torch.unsqueeze(torch.unsqueeze(torch.tensor(noisy),0), 0)).squeeze(), cmap=\"gray\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_idx = torch.randint(len(valid_dataset), size=(10,))\n",
    "cols = 5\n",
    "model.to('cpu')\n",
    "with torch.no_grad():\n",
    "    for i in range(3):\n",
    "        noisy,img = valid_dataset[sample_idx[i].item()]\n",
    "        figure = plt.figure()\n",
    "        figure.set_size_inches(16, 10)\n",
    "        figure.add_subplot(1, cols, 1)\n",
    "        plt.axis(\"off\")\n",
    "        plt.title('Noisy')\n",
    "        plt.imshow(noisy.squeeze(), cmap=\"gray\")\n",
    "        figure.add_subplot(1, cols, 2)\n",
    "        plt.axis(\"off\")\n",
    "        plt.title('Ground truth')\n",
    "        plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "        figure.add_subplot(1, cols, 3)\n",
    "        plt.axis(\"off\")\n",
    "        plt.title('Recon')\n",
    "        plt.imshow(model(torch.unsqueeze(torch.unsqueeze(torch.tensor(noisy),0), 0))[1].squeeze(), cmap=\"gray\")\n",
    "        figure.add_subplot(1, cols, 4)\n",
    "        plt.axis(\"off\")\n",
    "        plt.title('Lower')\n",
    "        plt.imshow(model(torch.unsqueeze(torch.unsqueeze(torch.tensor(noisy),0), 0))[0].squeeze(), cmap=\"gray\")\n",
    "        figure.add_subplot(1, cols, 5)\n",
    "        plt.axis(\"off\")\n",
    "        plt.title('Upper')\n",
    "        plt.imshow(model(torch.unsqueeze(torch.unsqueeze(torch.tensor(noisy),0), 0))[2].squeeze(), cmap=\"gray\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
